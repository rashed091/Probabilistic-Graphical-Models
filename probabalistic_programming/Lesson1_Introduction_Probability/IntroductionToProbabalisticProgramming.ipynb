{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Probabilistic Programming\n",
    "\n",
    "\n",
    "\n",
    "## CSCI E-83\n",
    "## Stephen Elston\n",
    "\n",
    "Real-world machine intelligence and machine learning operates in an uncertain world. Probabilistic programming encompasses a range of algorithms for making decisions and inferences under uncertainty. Probabilistic programming has multiple uses in machine learning and artificial intelligence. Probabilistic programming methods arise in problems in many areas including, scheduling, robotics, natural language processing and image understanding. \n",
    "\n",
    "This course will give you a background in the theory and practice of probabilistic programming, including:\n",
    "1. Develop the ability to apply probabilistic programming methods to machine intelligence and machine learning applications. \n",
    "2. Have an understanding of the theory that connects various probabilistic programming methods. \n",
    "3. Have hands-on experience applying probabilistic programming algorithms to various machine intelligence and machine learning problems. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About your instructional  staff\n",
    "\n",
    "**Steve Elston:** \n",
    "\n",
    "Steve is an experienced big data geek, data scientist, and machine learning and AI engineer with several decades of experience.  He creates and presents machine learning and artificial intelligence instructional material in his roles as instructor for the Harvard Extension and University of Washington, Oâ€™Reilly Author, Strata speaker, and an edX data science and machine learning instructor.  Steve provides data science and machine learning consulting to many companies from global enterprises to startups. He leads analytics projects, takes software products from concept and financing through on-shore and off-shore development, intellectual property protection, large client sales, customer shipment and support. He has founded companies and served in several senior management positions.   \n",
    "\n",
    "His experience includes:\n",
    "- Data science author, trainer and instructor.\n",
    "- R, Python, Bash.\n",
    "- SQL and NoSQL databases, Hadoop. \n",
    "- Git and Github.\n",
    "- Jupyter. \n",
    "- Machine learning and predictive analytics model construction and evaluation.\n",
    "- Artificial intelligence engineering.\n",
    "- Data exploration and visualization.\n",
    "- Scaling and performance tuning of large scale analytics systems. \n",
    "- Real-time analytics, streaming analytics, and Complex Event Processing (CEP). \n",
    "- Location-based analytics. \n",
    "- Large scale optimization. \n",
    "- Signal processing, image processing and machine vision.   \n",
    "- Financial market data analytics, risk models, portfolio optimization, time series models.\n",
    "- Electronic payment systems and fraud prevention. \n",
    "- Wireless telecom analytics and fraud detection.\n",
    "- Customer gift and loyalty systems.\n",
    "\n",
    "\n",
    "**Teaching Fellow:** \n",
    "\n",
    "**Jagriti  Kesarwani**, (pronounced as j-aa-g-r-ih-t-ee) means vigilance/awareness. Jagriti earned her Bachelors in Electronics and Communication Engineering from Motilal Nehru National Institute Of Technology (MNNIT), Allahabad, India. She is a Gold medal awardee for securing the first position in Electronics and Communication Engineering, Class of 2013 at MNNIT, Allahabad.\n",
    " \n",
    "Jagriti has been working at Goldman Sachs for over 5 years where she plays a dual role of a technology and business analyst. She is a full stack developer and an expert in not just defining and documenting business requirements but also translating them into cost-effective technical solutions in the HR domain.\n",
    " \n",
    "Jagriti is very passionate about traveling, so much so, that she has visited 22 countries in the last 3 years (along with a full-time job!). Jagriti also enjoys dancing and loves to learn new dance forms (Belly dancing is next on her list). Feel free to ask her about her travel experiences and she would be more than happy to narrate them to you.\n",
    "\n",
    "Jagriti is thrilled to be a part of HES and can't wait to see what adventures and experiences it will bring!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent model of machine intelligence\n",
    "\n",
    "A general model for **machine intelligence** or **artificial intelligence** involves an **agent** interacting with the **environment**. The agent uses **sensors** to acquire information on the environment and based on the **state** of the environment takes **actions** to change the state of the environment. A schematic representation of this simple model is shown in Figure 1 below. \n",
    "\n",
    "<img src=\"img/AgentModel.JPG\" alt=\"Drawing\" style=\"width:500px; height:300px\"/>\n",
    "<center> **Figure 1. General Agent Model** </center>\n",
    "\n",
    "At the minimum, the agent must have certain capabilities:\n",
    "\n",
    "1. A **Representation** of the model used by the agent to represent the relationships in the model. A good representation is often the key to good machine intelligence. A good representation is a mapping of the model and the environment. Graphical models provide an effective representation for many complex problems. Alternatively, so called **deep representations** produce powerful results in many situations. \n",
    "2. **Inference or reasoning** is the process of computing actions or decisions from **queries** of the model given the **evidence**. In the simplest form a query returns a mathematical result, such as the **marginal probability distribution** or the **maximum a posteriori** value. Reasoning computes a specific action which is applied to the environment. \n",
    "3. The agent performs **learning** using data or **evidence** to update the model. The evidence is observed by **sensors** which provide information to the model on the **state of the environment**. For graphical models, learning involves two distinct steps, learning the the structure of the model and learning parameters of the model. In graphical probabilistic models learning and inference are actually the same process.   \n",
    "\n",
    "A schematic of this simple agent model \n",
    "\n",
    "<img src=\"img/AIModel.JPG\" alt=\"Drawing\" style=\"width:500px; height:250px\"/>\n",
    "<center> **Schematic view of an agent** </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why probabilistic programming?\n",
    "\n",
    "\n",
    "Machine intelligence must operate in a world with. \n",
    "\n",
    "1. Data is often noisy or otherwise **uncertain**. A related problem is the possibility of **unreliable** evidence. Machine learning models must be resistant to unexpected and erroneous sensor inputs. In some cases, the uncertain or unreliable evidence are deliberately produced. This results in what is known as an **adversarial** situation. \n",
    "2. Unexpected situations occur on a regular basis. Often these 'unexpected situations' are simply cases just outside the set of training cases. Many machine learning models produce erroneous or unexpected results when faced with unexpected inputs; a situation known as **brittleness**.    \n",
    "3. Many real-world problems have a high degree of complexity which cannot be feasibly modeled explicitly. \n",
    "4. Models of many real-world systems include **unobservable** variables. There is no feasible way to obtain direct evidence on these variables. \n",
    "5. Optimizing complex processes requires a sequence of decisions. These decisions often must be made with uncertain and incomplete information. \n",
    "\n",
    "Probabilistic models provides a framework for a wide range of difficult problems including:\n",
    "\n",
    "1. Dealing gracefully with unexpected or erroneous inputs. Probabilistic models can exhibit robustness to unexpected inputs as each observation or piece of evidence is probability weighted. \n",
    "2. In many cases, probabilistic models can effectively represent highly complex problems. Conceptually, a probabilistic model 'smooths' over a certain amount of complexity allowing a relatively simple representation of a complex system. \n",
    "3. Inferences can be made on **unobservable** variables with probabilistic models. The **marginal probability distribution** of the unobservable variables can be estimated from the model. This process is known as making a **query** on the model. \n",
    "4. Prior information, such as input on **beliefs** from domain experts, can be used to supplement data or **evidence**. This allows models to work in data poor situations, or for modeling rare events. \n",
    "5. Probabilistic models can operate as **generative models**. A generative model computes new synthetic cases from an original training set. Ideally, the statistics of the generated data are identical to those generated by the real environment. \n",
    "6. The combination of **probabilistic models** and **utility theory** provides a framework for complex decisions under uncertainty. This capability gives "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision theory and probability\n",
    "\n",
    "Many AI problem require a decision to be made. In this case the agent makes an inference based on a probabilistic model. Based on this inference a **decision** to take an action is made by finding the maximum **utility** of the alternatives. The agent's decision process is then a combination of probability theory and utility theory. This decision making process is also referred to as **reasoning**.\n",
    "\n",
    "In particular, the combination of probabilistic Markov process and a utility function leads to a **Markov decision process** or **MDP**. The goal of these problems is to maximize the utility of a series of **decisions** in a system with a probabilistic model. \n",
    "\n",
    "In many practical situations multiple decisions must be made in a time sequence. These decisions are made using both uncertain and incomplete information. Optimizing such decisions requires the combination of probabilistic models and utility theory found in MDPs.  \n",
    "\n",
    "In many situations, the variable we wish to control is **unobservable**. For example, we may need to control the torque of a robot's arm motor. The torque is unobservable, but other variables like the voltage on the motor, and dynamical information on the arms position, velocity and acceleration are all observable with sensors. We can model the behavior of the arm as a **partially observable Markov decision process** or **POMDP**.\n",
    "\n",
    "Optimal MDP solutions can be found by a number of algorithms. **Dynamic programming** algorithms are the most widely used methods. However, dynamic programming is limited to cases where a probabilistic model for the system being acted on can be modeled completely. An alternative that has emerged in recent years is **reinforcement learning** which can only requires a **utility function** and does not require an explicit probabilistic model.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning in probabilistic models\n",
    "\n",
    "Learning is at the core of probabilistic models. A variety of machine learning algorithms are available for learning with probabilistic models. In general there is a trade-off between computational complexity and accuracy.      \n",
    "\n",
    "### Learning for graphical models\n",
    "\n",
    "There are two distinct aspects of the specification process of graphical models:\n",
    "\n",
    "The **quantitative specification** which defines the details of the conditional distributions. For Bayesian graphical models, the quantitative specification is created using a combination of prior information and evidence. Luckily for us, there are computationally efficient exact and approximate algorithms. There are, in fact, two broad classes of learning algorithms for graphical models, exact and approximate. Exact methods are useful for smaller problems with discrete probability distributions. Approximate methods can scale to larger problems and accommodate continuous distributions.      \n",
    "\n",
    "\n",
    "### Learning for Markov decision processes\n",
    "\n",
    "There are two categories of algorithms used for optimizing Markov Decision Processes, or MDPs. The first, and most widely used class, are **dynamic programming** methods. Dynamic programming algorithms require a completely specified probability model. Given such a model, dynamic programming algorithms perform an efficient search for a sequence of optimal decisions. \n",
    "\n",
    "In contrast to dynamic programming, **reinforcement learning** algorithms do not require a specified probability model. Reinforcement learning is in a class of algorithms know as **function approximation** methods. These algorithms attempt to learn complex functions to relate data inputs to posterior values or outputs. In effect, reinforcement learning algorithms learn the probability model from data. Inherently, these models have a large number of parameters which must be determined in the training process. Thus, reinforcement learning algorithms trade-off no requirement for a model for computational complexity. \n",
    "\n",
    "Reinforcement learning models are trained using a utility function. It is this utility function which must be approximated. However, the relationship between observable variables and the utility function is complex and inherently nonlinear. As a result of the inherent complexity training reinforcement learning models is both computationally intensive and requires vast amounts of data. These facts limits the problems to which reinforcement learning can be applied. Creating more general algorithms for training reinforcement learning models is an active area of research.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copyright 2018, Stephen F Elston. All rights reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
