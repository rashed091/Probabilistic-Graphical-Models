{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "\n",
    "## Graphical Parameters and Model Structure\n",
    "\n",
    "In the previous homework, you performed queries on a graphical model of possible murders and murder weapons. Now, you will estimate model parameters and structure using data.   \n",
    "\n",
    "As a reminder, the joint probability distribution is:\n",
    "\n",
    "$$p(B,C,BW,CW,M)$$     \n",
    "\n",
    "where the letters indicate the following variables;   \n",
    "$B = $ butler committed the crime, {not murderer, murderer},   \n",
    "$C = $ cook committed the crime, {not murderer, murderer},    \n",
    "$BW = $ choice of weapon, {knife, knife with poison}, conditional on butler,  \n",
    "$CW = $ choice of weapon, {knife, knife with poison}, conditional on cook,   \n",
    "$M = $ murderer {butler or cook, third party alone, combination of butler or cook and third party}.    \n",
    "\n",
    "Keeping in mind it is possible the cook, the butler and the third party could be guilty, and that participation in the crime in any capacity constitutes guilt, the distribution can be factorized in the following manner:\n",
    "\n",
    "$$p(B,C,BW,CW,M) = p(B)\\ p(C)\\ p(BW\\ |\\ B)\\ p(CW\\ |\\ C)\\ p(M\\ |\\ BW,CW, C, W)$$  \n",
    "\n",
    "A graph of the model is shown below. \n",
    "\n",
    "<img src=\"MurderDirected.JPG\" alt=\"Drawing\" style=\"width:600px; height:300px\"/>\n",
    "<center> **DAG for murder evidence** </center>\n",
    "\n",
    "Notice that the skeleton of this graph does not have a tree structure. This fact will limit how well estimation algorithms will work, particularly for graph structure. Keep this fact in mind as you proceed. \n",
    "\n",
    "As a first step execute the code in the below to simulate the 20 cases for the dataset. Examine the code to see the CPD tables for this simulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Simulate the binary tables\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import pandas as pd\n",
    "\n",
    "def sim_bernoulli(p, n = 25):\n",
    "    \"\"\"\n",
    "    Function to compute the vectors with probabilities for each \n",
    "    condition (input value) of the dependent variable using the Bernoulli\n",
    "    distribution. \n",
    "    \n",
    "    The arguments are:\n",
    "    p - a vector of probabilites of success for each case.\n",
    "    n - The numer of realizations. \n",
    "    \"\"\"\n",
    "    temp = np.zeros(shape = (len(p), n))\n",
    "    for i in range(len(p)): \n",
    "        temp[i,:] = nr.binomial(1, p[i], n)\n",
    "    return(temp)\n",
    "\n",
    "def selec_dist_1(sims, var, lg):\n",
    "    \"\"\"\n",
    "    Function to integrate the conditional probabilities for\n",
    "    each of the cases of the parent variable. \n",
    "    \n",
    "    The arguments are:\n",
    "    sims - the array of simulated realizations with one row for each state of the\n",
    "           parent variable. \n",
    "    var - the vector of values of parent variable used to select the value from the \n",
    "          sims array.\n",
    "    lg - vector of states of possible states of the parent variable. These must be\n",
    "         in the same order as for the sims array. \n",
    "    \"\"\"\n",
    "    out = sims[0,:] # Copy of values for first parent state\n",
    "    var = np.array(var).ravel()\n",
    "    for i in range(1, sims.shape[0]): # loop over other parent states\n",
    "        out = [x if u == lg[i] else y for x,y,u in zip(sims[i,:], out, var)]\n",
    "    return([int(x) for x in out])\n",
    "\n",
    "def set_class_2(x):\n",
    "    \"\"\"\n",
    "    Function to flatten the array produced by the numpy.random.multinoulli function. \n",
    "    The function tests which binary value of the array of output states is true\n",
    "    and substitutes an integer for that state. This function only works for up to three\n",
    "    output states. \n",
    "    \n",
    "    Argument:\n",
    "    x - The array produced by the numpy.random.multinoulli function. \n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for i,j in enumerate(x):\n",
    "        if j[0] == 1: out.append(0)\n",
    "        elif j[1] == 1: out.append(1)\n",
    "        else: out.append(2)       \n",
    "    return(out)   \n",
    "\n",
    "def sim_multinoulli(p, n = 25):\n",
    "    \"\"\"\n",
    "    Function to compute the vectors with probabilities for each \n",
    "    condition (input value) of the dependent variable using the multinoulli\n",
    "    distribution. \n",
    "    \n",
    "    The arguments are:\n",
    "    p - an array of probabilites of success for each possible combination\n",
    "        of states of the parent variables. Each row in the array are the \n",
    "        probabilities for each state of the multinoulli distribution for \n",
    "        that combination of parent values.\n",
    "    n - The numer of realizations. \n",
    "    \"\"\"\n",
    "    temp = np.zeros(shape = (p.shape[0], n))\n",
    "    for i in range(p.shape[0]):  \n",
    "        ps = p[i,:]\n",
    "        mutlis = nr.multinomial(1, ps, n) \n",
    "        temp[i,:] = set_class_2(mutlis)\n",
    "    return(temp)\n",
    "\n",
    "def selec_dist_4(sims, var1, var2, var3, var4, lg1, lg2, lg3, lg4):\n",
    "    \"\"\"\n",
    "    Function to integrate the conditional probabilities for\n",
    "    each of the cases of four parent variables. \n",
    "    \n",
    "    The arguments are:\n",
    "    sims - the array of simulated realizations with one row for each state of the\n",
    "           union of the parent variables. \n",
    "    var1 - the vector of values of first parent variable used to select the value from the \n",
    "          sims array.\n",
    "    var2 - the vector of values of second parent variable used to select the value from the \n",
    "          sims array.\n",
    "    var3 - the vector of values of third parent variable used to select the value from the \n",
    "          sims array.\n",
    "    var4 - the vector of values of fourth parent variable used to select the value from the \n",
    "          sims array.\n",
    "    lg1 - vector of states of possible states of the first parent variable. These must be\n",
    "         in the same order as for the sims array. \n",
    "    lg2 - vector of states of possible states of the second parent variable. These must be\n",
    "         in the same order as for the sims array. \n",
    "    lg3 - vector of states of possible states of the third parent variable. These must be\n",
    "         in the same order as for the sims array. \n",
    "    lg4 - vector of states of possible states of the fourth parent variable. These must be\n",
    "         in the same order as for the sims array. \n",
    "    \"\"\"\n",
    "    out = sims[0,:] # Copy values for first combination of states for parent variables\n",
    "    \n",
    "    ## make sure the parent variables are 1-d numpy arrays.\n",
    "    var1 = np.array(var1).ravel() \n",
    "    var2 = np.array(var2).ravel()\n",
    "    var3 = np.array(var3).ravel() \n",
    "    var4 = np.array(var4).ravel()\n",
    "    for i in range(1, sims.shape[0]): # Loop over all combination of states of the parent variables\n",
    "        out = [x if t == lg1[i] and u == lg2[i] and v == lg3[i] and w == lg4[i] else y for x,y,t,u,v,w in \n",
    "              zip(sims[i,:], out, var1, var2, var3, var4)]                         \n",
    "    return([int(x) for x in out])\n",
    "\n",
    "\n",
    "## set the sample size\n",
    "nsamp = 20\n",
    "\n",
    "## First the conditionally independent variables\n",
    "nr.seed(22234)\n",
    "B_samps = pd.DataFrame(nr.binomial(1, 0.8, nsamp), columns = ['B'])\n",
    "nr.seed(2355)\n",
    "C_samps = pd.DataFrame(nr.binomial(1, 0.3, nsamp), columns = ['C'])\n",
    "\n",
    "## Two variables conditionally depenent on one other\n",
    "probs = [0.5, 0.1]\n",
    "nr.seed(2134)\n",
    "bern = sim_bernoulli(probs, nsamp)\n",
    "BW_samps = pd.DataFrame(selec_dist_1(bern, B_samps, [0,1]), columns = ['BW'])\n",
    "\n",
    "probs = [0.5, 0.7]\n",
    "nr.seed(22234)\n",
    "bern = sim_bernoulli(probs)\n",
    "CW_samps = pd.DataFrame(selec_dist_1(bern, C_samps, [0,1]), columns = ['CW'])\n",
    "\n",
    "\n",
    "probs = np.array([[0.0, 0.7, 0.5,  0.7, 0.0, 0.6, 0.5,  0.6, 0.0, 0.7, 0.5,  0.7, 0.0, 0.6, 0.5,  0.6],\n",
    "                           [1.0, 0.0, 0.0,  0.0, 1.0, 0.0, 0.0,  0.0, 1.0, 0.0, 0.0,  0.0, 1.0, 0.0, 0.0,  0.0],\n",
    "                           [0.0, 0.1, 0.4,  0.2, 0.0, 0.1, 0.3,  0.2, 0.0, 0.1, 0.4,  0.2, 0.0, 0.1, 0.3,  0.2]]).transpose()\n",
    "\n",
    "nr.seed(2334)\n",
    "sims = sim_multinoulli(probs, nsamp)\n",
    "\n",
    "C_lg = [0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1]\n",
    "B_lg = [0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1]\n",
    "BW_lg = [0,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1]\n",
    "CW_lg = [0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1]\n",
    "M_samps = pd.DataFrame(selec_dist_4(sims, B_samps, C_samps, BW_samps, CW_samps, B_lg, C_lg, BW_lg, CW_lg), columns = ['M'])\n",
    "\n",
    "\n",
    "\n",
    "## Now concatenate the columns into one data frame\n",
    "dats = pd.concat([B_samps, C_samps, BW_samps, CW_samps, M_samps], axis = 1)\n",
    "print(dats.shape)\n",
    "dats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Parameter Estimation\n",
    "\n",
    "With the dataset generated you will now estimate the parameters of the graphical model using both maximum likelihood and Bayesian methods. \n",
    "\n",
    "As a first step execute the code in the cell below to load the packages you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator, BayesianEstimator\n",
    "from pgmpy.inference import BeliefPropagation\n",
    "from pgmpy.estimators import HillClimbSearch, BicScore, K2Score, StructureScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create and execute the code in the cell below to estimate and display the parameters of the CPDs using the graph structure previously shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine these results and answer the following questions:\n",
    "1. How many parameters are there in the CPD tables?\n",
    "2. Given the number of cases, is this MLE problem underdetermined? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS 1:     \n",
    "ANS 2: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will estimate the CPD parameters using the Bayesian estimator. For this first estimate use the following moderately weak and uniform prior distributions (pseudo counts):\n",
    "\n",
    "- C: {4,4}\n",
    "- B: {4,4}\n",
    "- CW: {4,4}\n",
    "- BW: {4,4}\n",
    "- M: {2,2,2}\n",
    "\n",
    "In the cell below create and execute the code to perform Bayes estimation and display the CPD parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focus your attention on the M CPD. In terms of extreme values, how does the table computed with the Bayesian method compare to the table computed with MLE? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next verify that the independencies of all the variables in your model are correct using the `local_independencies` method. Create and execute the code in the cell below to display the independencies in the CPD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Is your graph an I-map of the distribution and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to perform inference on your model. Use the belief propagation method to query the M variable with evidence that the cook is not the murderer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this resulting marginal distribution to the marginal distribution you obtained for the same query in the previous homework using the CDP tables provided. How do these distribution differ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will estimate the CPD parameters using the Bayesian estimator with a moderately weak but biased prior distribution. For this first estimate use the following moderately weak and uniform prior distributions (pseudo counts):\n",
    "\n",
    "- C: {2,1}\n",
    "- B: {1,2}\n",
    "- CW: {1,2}\n",
    "- BW: {2,1}\n",
    "- M: {2,1,2}\n",
    "\n",
    "In the cell below create and execute the code to perform Bayes estimation and display the CPD parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the parameters in the M CPD table to the estimate with a uniform prior. How are these different, and is this expected given the change in prior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the belief propagation method to query the M variable with evidence that the cook is not the murderer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this marginal distribution to the one obtained with the a uniform prior. In general, are the differences what you would expect, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "Now you will explore how well the structure of the graph can be estimated. **Keep in mind that the graph used for the simulation is not a tree**. Further, your estimates of graph structure may differ from results obtained in other environment. Answer the questions based on the results you find. \n",
    "\n",
    "As a first step, execute the code i the cell below to create a simulated dataset with 2000 cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set the sample size\n",
    "nsamp = 2000\n",
    "\n",
    "## First the conditionally independent variables\n",
    "nr.seed(22234)\n",
    "B_samps = pd.DataFrame(nr.binomial(1, 0.8, nsamp), columns = ['B'])\n",
    "nr.seed(2355)\n",
    "C_samps = pd.DataFrame(nr.binomial(1, 0.3, nsamp), columns = ['C'])\n",
    "\n",
    "## Two variables conditionally depenent on one other\n",
    "probs = [0.5, 0.1]\n",
    "nr.seed(2134)\n",
    "bern = sim_bernoulli(probs, nsamp)\n",
    "BW_samps = pd.DataFrame(selec_dist_1(bern, B_samps, [0,1]), columns = ['BW'])\n",
    "\n",
    "probs = [0.5, 0.7]\n",
    "nr.seed(22234)\n",
    "bern = sim_bernoulli(probs)\n",
    "CW_samps = pd.DataFrame(selec_dist_1(bern, C_samps, [0,1]), columns = ['CW'])\n",
    "\n",
    "\n",
    "probs = np.array([[0.0, 0.7, 0.5,  0.7, 0.0, 0.6, 0.5,  0.6, 0.0, 0.7, 0.5,  0.7, 0.0, 0.6, 0.5,  0.6],\n",
    "                           [1.0, 0.0, 0.0,  0.0, 1.0, 0.0, 0.0,  0.0, 1.0, 0.0, 0.0,  0.0, 1.0, 0.0, 0.0,  0.0],\n",
    "                           [0.0, 0.1, 0.4,  0.2, 0.0, 0.1, 0.3,  0.2, 0.0, 0.1, 0.4,  0.2, 0.0, 0.1, 0.3,  0.2]]).transpose()\n",
    "\n",
    "nr.seed(2334)\n",
    "sims = sim_multinoulli(probs, nsamp)\n",
    "\n",
    "C_lg = [0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1]\n",
    "B_lg = [0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1]\n",
    "BW_lg = [0,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1]\n",
    "CW_lg = [0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1]\n",
    "M_samps = pd.DataFrame(selec_dist_4(sims, B_samps, C_samps, BW_samps, CW_samps, B_lg, C_lg, BW_lg, CW_lg), columns = ['M'])\n",
    "\n",
    "\n",
    "\n",
    "## Now concatenate the columns into one data frame\n",
    "dats_big = pd.concat([B_samps, C_samps, BW_samps, CW_samps, M_samps], axis = 1)\n",
    "print(dats_big.shape)\n",
    "dats_big.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dataset simulated, you will now try estimating the model structure. Use the hill climb search algorithm along with the the BIC scoring function to estimate the model structure. Create and execute the code in the cell below to estimate the model structure and display the identified edges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine these edges. Clearly, this structure is quite different from the structure used for the simulation. Keeping in mind the butler is much more likely to be the murderer compared to the cook, does this structure make sense and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How good is this structure fit? To answer this question you will need to compare the BIC score of the graph used for the simulation with the BIC score of the estimated structure. You must create a baseline DAG structure and compare the BIC score to the score of the estimated model. \n",
    "\n",
    "In the cell below create the code to define a baseline DAG and compute and display the BIC score of both graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has the BIC score changed significantly? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will apply the K2 score method to the large dataset. In the cell below, create the code to use the hill climbing search with the K2 score to estimate and display the model structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this graph structure any different from the one obtained with fewer cases?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: The structure is the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compare the K2 score for the baseline model with the estimated model using the larger dataset for both cases. In the cell below create and execute the code to compute and display these scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are these K2 scores different? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below create and execute the code to display the independencies of the graph structure you have found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, compare the BIC and K2 scores of the two models you created with the K2 and BIC score methods on the large dataset. In the cell below create and execute the code to compute and display these 4 scores.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there any substantial differences between the scores of these two models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: No, they are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
